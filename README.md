# üîç Explainable AI for Real-Time Clinical Decision Support in Predicting 30-Day Readmission for Diabetic Patients.

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)
![Jupyter](https://img.shields.io/badge/Notebook-Jupyter-orange?logo=jupyter)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Project-Research%20Prototype-yellow)
![Models](https://img.shields.io/badge/Models-LR%20%7C%20RF%20%7C%20MLP%20%7C%20XGBoost-red)
![SMOTE](https://img.shields.io/badge/SMOTE-Applied-blueviolet)
![SHAP](https://img.shields.io/badge/Explainability-SHAP-red)

This project develops machine learning models to predict hospital readmissions using real-world clinical encounter data and explains model behavior using SHAP.  
A UI was **not** implemented due to moderate model performance, focusing instead on explainability and model diagnostics.

---

## 1. Project Overview

The goal is to predict hospital readmissions categorized as:

- **0** ‚Üí No readmission  
- **1** ‚Üí Readmitted within 30 days  
- **2** ‚Üí Readmitted after 30 days  

The project focuses on:

- Patient-level train/test splits (no leakage)  
- Class balancing with SMOTE  
- Feature engineering for clinical interpretability  
- Machine learning experimentation with four models  
- SHAP-based global + local interpretability  

---

## 2. Dataset

**Source:** UCI Diabetes Readmission Dataset  
üîó https://archive.ics.uci.edu/dataset/296/diabetic+data

Key properties:

- ~100,000 hospital encounters  
- Unique `patient_nbr` allows patient-level splitting  
- Contains diagnoses, medications, demographics, and lab measures  
- Three-class readmission target  

**Validation checks done:**

- Missingness patterns  
- Outlier detection  
- Duplicate encounter removal  
- Logical range checks  
- Diagnosis and medication consistency  

---

## 3. Workflow Summary

### 3.1 Data Cleaning & Initial Preprocessing
- Standardized column names  
- Handled missing values  
- Recoded categories  
- Removed invalid/outlier values  
- Filtered implausible encounter records  

---

### 3.2 üß™ Exploratory Data Analysis (EDA)

Performed **after initial preprocessing**.

**Univariate Analysis:**  
- Numerical distributions  
- Categorical counts  
- Demographic summaries  

**Bivariate Analysis:**  
- Correlations  
- Feature vs. target relationships  

**Class imbalance identified (training set):**

| Class | Count |
|-------|-------|
| 0 | 8,655 |
| 1 | 27,274 |
| 2 | 41,794 |

---

### 3.3 üîß Feature Engineering

Added interpretable clinical features:

- Age brackets  
- Comorbidity score  
- Total medications  
- Diagnosis grouping  
- Encounter frequency  
- Severity groupings  

---

### 3.4 üîê Patient-Level Train/Test Split

Used **GroupShuffleSplit** to ensure:

- Same patient **never** appears in both sets (train and test)  
- No leakage from repeated encounters  
- More realistic generalization performance  

---

### 3.5 üß¨ Balancing With SMOTE

Applied **only on training data** to avoid leakage.

Balanced class counts:  
‚Üí **All classes oversampled to 41,794**  

---

### 3.6 üìè Scaling

- **Scaled:** Logistic Regression, MLP  
- **Unscaled:** Random Forest, XGBoost  

---

### 3.7 ‚öôÔ∏è Model Training

Models trained:

1. Logistic Regression  
2. Random Forest (GridSearchCV)  
3. MLP Classifier (GridSearchCV)  
4. XGBoost Classifier (GridSearchCV)

---

### 3.8 üìä Evaluation

Reported (Macro):

- Accuracy  
- Precision  
- Recall  
- F1 Score  
- ROC AUC  

**Best model:**  
‚≠ê **XGBoost** ‚Äî AUC ~0.66  
But overall performance remains moderate.

---

### 3.9 üß† Explainable AI (SHAP)

**Global Explanations:**  
- Summary bar plots  
- Feature importance rankings  
- Feature dependence  

**Local Explanations:**  
- Sample-level waterfall plots  
- Case-specific interpretation  

Strong emphasis on **interpretability over deployment**.

---

## 4. Results Summary

| Model | AUC Macro | Notes |
|--------|------------|-------|
| Logistic Regression | ~0.59 | Weak signal |
| Random Forest | ~0.65 | Better but unstable |
| MLP Classifier | ~0.62 | Overfits easily |
| **XGBoost** | **~0.66** | Best performer |

**Conclusion:** Predictions remain noisy and unreliable for clinical deployment.

---

## 5. Why No UI Was Built

Building a clinical UI requires:

- High recall for critical cases  
- Strong predictive power  
- Explainability and stability  
- Low risk of misclassification  

Since the models achieve only **moderate accuracy and AUC**, deploying a UI would create a false sense of reliability.  
Thus, we prioritized **explainability, diagnostics, and data understanding** instead.

---

## 6. Next Steps

### ‚≠ê Data Enhancements
- Add temporal features  
- Incorporate longitudinal patient histories  
- Extract richer comorbidity metrics  
- Use visit sequences  

### ‚≠ê Modeling Enhancements
- Try LSTM/GRU sequence models  
- Feature selection  
- Calibration (Platt scaling, isotonic regression)  

### ‚≠ê XAI Enhancements
- SHAP interaction values  
- Counterfactual explanations  
- Monitoring & drift detection  

### ‚≠ê Deployment (After Further Improvements)
- UI for real-time CDS  
- Workflow-integrated alerts  
- Model monitoring dashboards  

---

## 7. Project Structure


